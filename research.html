<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="main.css" type="text/css" />
<link rel="stylesheet" href="font-awesome/css/font-awesome.min.css">
<!--- <title></title> --->
<title>Wentao XIE</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<div id="main-container">
<div id="header-container">
<div id="header">
<div id="header-icon-text-container">
<div id="header-icon-container" >
<a href="index.html"><img src="./images/hkust.jpg" alt="" style="width: 100%; height: 100%; position: center; padding:0px; margin: 0px;"></a>
</div>
<div id="header-text-container">
<a href="index.html">Wentao Xie</a>
</div>
</div>
<div id="main">
<button class="openbtn" onclick="openNav()">☰</button>
</div>
</div>
</div>
<div id="layout">
<div id="layout-menu-container">
<div id="layout-menu">
<div class="menu-item"><a href="javascript:void(0)" class="closebtn" onclick="closeNav()">×</a></div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="research.html" class="current">Research</a></div>
</div> <!-- <div id="layout-menu"> -->
</div> <!-- <div id="layout-menu-container"> -->
<div id="layout-content-container">
<div id="layout-content">
<h1>Research</h1>
<div id="text-img-container"><div id="img-container">
<img src="images/focus.png" alt="alt text" width="300px" height="225px" /></div>
<div id="text-container"><p>My research focuses on human-centric ubiquitous computing, with an emphasis on using Internet of Things (IoT) sensors to empower interaction and healthcare applications. In particular, I am interested in using IoT sensors to interpret and understand <b>physical</b> and <b>physiological</b> human behaviors. </p>
<p>Currently, I am working on the following two directions: </p>
<ol>
<li><p>Immersive HCI techniqes and </p>
</li>
<li><p>Smart pulmonary disease management.</p>
</li>
</ol>
</div></div>
<h2>Immersive HCI Techniqes</h2>
<div id="text-img-container"><div id="img-container">
<img src="images/projects/rimsense.jpg" alt="alt text" width="300px" height="180px" /></div>
<div id="text-container"><h4>RimSense: Enabling Touch-based Interaction on Eyeglass Rim Using Piezoelectric Sensors</h4>
<p>W Xie, H Chen, J Wei, J Zhang, Q Zhang (IMWUT/UbiComp 2024) <br />
<i>RimSense supports touch gestures on the eyeglass rim using piezoelectric sensors. This design enables direct manipulation-based interaction.</i> &nbsp; <a href="pub/RimSense.pdf" target=&ldquo;blank&rdquo;>Paper</a> &nbsp; <a href="https://youtu.be/W5R63hINpy0" target=&ldquo;blank&rdquo;>Demo</a></p>
</div></div>
<div id="text-img-container"><div id="img-container">
<img src="images/projects/blear.jpg" alt="alt text" width="300px" height="180px" /></div>
<div id="text-container"><h4>BLEAR: Practical Wireless Earphone Tracking under BLE protocol</h4>
<p>L Ge, W Xie, J Zhang, Q Zhang (PerCom 2024) <br />
<i>BLEAR is an earphone-based position tracking system which can truly be adopted under the BLE protol with restricted sampling rate.</i> <br /></p>
</div></div>
<div id="text-img-container"><div id="img-container">
<img src="images/projects/fasense.jpg" alt="alt text" width="300px" height="180px" /></div>
<div id="text-container"><h4>Acoustic-based Upper Facial Action Recognition for Smart Eyewear</h4>
<p>W Xie, Q Zhang, J Zhang (IMWUT/UbiComp 2021) <br />
<i>Fasense is a smart eyewear design that incorporates pairs of acoustic sensors to sense upper facial actions for immersive interaction.</i> <br />
<a href="pub/imwut21.pdf" target=&ldquo;blank&rdquo;>Paper</a> &nbsp; <a href="https://youtu.be/-vXfif4fTC0" target=&ldquo;blank&rdquo;>Talk</a> &nbsp; <a href="https://youtu.be/vee5qgRjuD4" target=&ldquo;blank&rdquo;>Demo</a></p>
</div></div>
<h2>Smart Pulmonary Disease Management</h2>
<div id="text-img-container"><div id="img-container">
<img src="images/projects/deepbreath.jpg" alt="alt text" width="300px" height="180px" /></div>
<div id="text-container"><h4>DeepBreath: Breathing Exercise Assessment with a Depth Camera</h4>
<p>W Xie, C Xu, Y Gong, Y Wang, Y Liu, J Zhang, Q Zhang, Z Zheng, S Yang (IMWUT/UbiComp 2024) <br />
<i>DeepBreath is a depth camera-based breathing training system that can measure breathing rate, breathing volume and breathing mode (chest/belly).</i> &nbsp; <a href="https://youtu.be/dVF4P_ivHFM" target=&ldquo;blank&rdquo;>Demo</a></p>
</div></div>
<div id="text-img-container"><div id="img-container">
<img src="images/projects/earspiro.jpg" alt="alt text" width="300px" height="180px" /></div>
<div id="text-container"><h4>EarSpiro: Earphone-based Spirometry for Lung Function Assessment</h4>
<p>W Xie, Q Hu, J Zhang, Q Zhang (IMWUT/UbiComp 2022) <br />
<i>EarSpiro is a cost-efficient pulmonary function test (PFT) method with a pair of mic-caring earphones. EarSpiro can estimate F-V curves and PFT indicators.</i> &nbsp; <a href="pub/imwut22.pdf" target=&ldquo;blank&rdquo;>Paper</a> &nbsp; <a href="https://youtu.be/TBICgka-uh4" target=&ldquo;blank&rdquo;>Demo</a></p>
</div></div>
<div id="text-img-container"><div id="img-container">
<img src="images/projects/rhythm.jpg" alt="alt text" width="300px" height="180px" /></div>
<div id="text-container"><h4>Noncontact Respiration Detection Leveraging Music and Broadcast Signals</h4>
<p>W Xie, R Tian, J Zhang, Q Zhang (IoTJ 2020) <br />
<i>This work presents a breathing rate estimation methods with a pair of microphone and speaker, with any music pieces.</i> <br /> 
<a href="pub/iotj21.pdf" target=&ldquo;blank&rdquo;>Paper</a></p>
</div></div>
<h2>Others</h2>
<div id="text-img-container"><div id="img-container">
<img src="images/projects/pdassess.jpg" alt="alt text" width="300px" height="180px" /></div>
<div id="text-container"><h4>PDAssess: A Privacy-preserving Free-speech based Parkinson’s Disease Daily Assessment System”</h4>
<p>B Yang, Q Hu, W Xie, X Wang, W Luo, Q Zhang (SenSys 2023) <br />
<i>PDAssess is a free speech-based Parkinson’s Disease (PD) severity assessment system, which can be installed on commodity smart speakers.</i> </p>
</div></div>
</div> <!-- <div id="layout-content"> -->
<div id="footer-container">
<div id="footer">
<div id="footer-text">
Last edited  on September 9<sup>th</sup> 2024  06:54PM (Time Zone: HKT). </br>
Powered by <a href="https://github.com/szl2/jemdoc-new-design" target="blank">jemdoc + new design</a>.
</div> <!-- <div id="footer-text"> -->
</div> <!-- <div id="footer"> -->
</div> <!-- <div id="footer-container"> -->
</div> <!-- <div id="layout-content-container"> -->
</div> <!--- <div id="layout"> --->
</div> <!--- <div id="main-container"> --->
<script>
function openNav() {
    if (window.innerWidth <= 1200) {
        document.getElementById("layout-menu").style.width = "280px";
        document.getElementById("layout-content-container").style.marginLeft = "280.8px";
        document.getElementById("layout-content-container").style.position = "fixed";
    }
}
function closeNav() {
    if (window.innerWidth <= 1200) {
        document.getElementById("layout-menu").style.width = "0";
        document.getElementById("layout-content-container").style.position = "static";
        document.getElementById("layout-content-container").style.marginLeft = "0px";
        setInterval(
            function(){ location.reload() },
            500
        );
    }
}
</script>
</body>
</html>
